{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MDI343\n",
    "## Lab on real-world graph analysis -- clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this lab is to get a feeling of real-world graphs. For information on the `scikit-network` library, [the documentation is handy](https://scikit-network.readthedocs.io/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sknetwork as skn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Util function to plot the inverse cumulative distribution\n",
    "def ccdf(values):\n",
    "    x = []\n",
    "    y = []\n",
    "    values = sorted(values)\n",
    "\n",
    "    # First make dist\n",
    "    dist = [(key, len(list(group))) for key, group in groupby(values)]\n",
    "\n",
    "    # Then compute inverse cumulative\n",
    "    total = 1.0\n",
    "    for (val, count) in dist:\n",
    "        x.append(val)\n",
    "        y.append(total)\n",
    "        total -= count/len(values)\n",
    "    return x, y\n",
    "\n",
    "# Util function to return the distribution of values\n",
    "def dist(values):\n",
    "    values = sorted(values)\n",
    "\n",
    "    # First make dist\n",
    "    dist = [(key, len(list(group))) for key, group in groupby(values)]\n",
    "    \n",
    "    return [x[0] for x in dist], [x[1] for x in dist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work on 2 graphs induced by the [Vital articles of Wikipedia](https://en.wikipedia.org/wiki/Wikipedia:Vital_articles/Level/4), a selection of about 10,000 articles of the English Wikipedia:\n",
    "* the directed graph of hyperlinks between these articles,\n",
    "* the bipartite graph between articles and (stemmed) words used in their summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['names_col', 'adjacency', 'names', 'labels', 'names_row', 'names_labels_hierarchy', 'meta', 'names_labels', 'labels_hierarchy', 'biadjacency'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = skn.data.load_netset('wikivitals')\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10012x10012 sparse matrix of type '<class 'numpy.bool_'>'\n",
       "\twith 792091 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# graph of links\n",
    "adjacency = data.adjacency\n",
    "adjacency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10012x31323 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 995919 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# graph of words\n",
    "biadjacency = data.biadjacency\n",
    "biadjacency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# article names\n",
    "names = data.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['People', 'History', 'Geography', 'Arts',\n",
       "       'Philosophy and religion', 'Everyday life',\n",
       "       'Society and social sciences', 'Biology and health sciences',\n",
       "       'Physical sciences', 'Technology', 'Mathematics'], dtype='<U27')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# article categories\n",
    "categories = data.names_labels\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['moos', 'tonnag', 'separatist', ..., 'luteum', 'radiat', 'helena'],\n",
       "      dtype='<U22')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# words\n",
    "words = data.names_col\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_index = {name:i for i, name in enumerate(names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_articles, n_words = biadjacency.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do\n",
    "\n",
    "For the 2 graphs:\n",
    "* Cluster the graph.\n",
    "* Compute some statistics about the clustering: how many clusters are there? Are they balanced (in number of nodes? in number of edges?)\n",
    "* Using PageRank, display the 5 most important nodes of each cluster.\n",
    "* Evaluate the quality of the clustering using the categories as ground-truth.\n",
    "* What does the ARI score mean? Do we have a good clustering? How can we know?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import adjusted_rand_score as ari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "louvain = skn.clustering.Louvain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Louvain(resolution=1.0, modularity='dugue', tol_aggregation=0.001, n_aggregations=-1, shuffle_nodes=False, sort_clusters=True, return_membership=True, return_aggregate=True)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "louvain.fit(adjacency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3018954851357631"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ari(labels, louvain.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A bit of comparison\n",
    "`scikit-network` also implements a clustering method based on the _$k$-means_ algorithm. As you know, graphs are not metric spaces, and so any method must first project the graph to a metric space, then run $k$-means on this space.\n",
    "\n",
    "For the 2 graphs:\n",
    "   * Run a $k$-means clustering.\n",
    "   * Compute the same base statistics about the clusters (as for Louvain); what can you say?\n",
    "   * Set up a method to compare the clusters obtained through $k$-means and Louvain. Can you say one is better than the other? In which regard(s)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
